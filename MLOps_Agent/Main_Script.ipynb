{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/datarobot-community/mlops-examples/blob/master/MLOps%20Agent/Main_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Agent - Python End to End\n",
    "**Author**: Matthew Cohen\n",
    "\n",
    "#### Scope\n",
    "The scope of this Notebook is to provide instructions on how to use DataRobot's MLOps Agents. \n",
    "\n",
    "#### Requirements\n",
    "\n",
    "- Python 3.7.0\n",
    "- MLOps Agent 6.3.3\n",
    "\n",
    "Your version might be different but the below procedure should remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone the repository\n",
    "!git clone https://github.com/datarobot-community/mlops-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install needed packages\n",
    "!pip install -r /content/mlops-examples/MLOps_Agent/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Agent\n",
    "\n",
    "To configure the agent, we just need to define the DataRobot MLOps location and our API token. By default, the agent expects the data to be spooled on the local file system. Make sure that default location (/tmp/ta) exists.\n",
    "\n",
    "The `token` needs to be your personal token found under Developer Tools in your DataRobot instance. The endpoint specified below is the DataRobot trial endpoint but you should change it if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"YOUR_API_TOKEN\"\n",
    "endpoint = \"https://app2.datarobot.com\"\n",
    "## connect to DataRobot platform with python client. \n",
    "client = dr.Client(token, \"{}/api/v2\".format(endpoint))\n",
    "\n",
    "mlops_agents_tb = client.get(\"mlopsInstaller\")\n",
    "with open(\"/content/mlops-examples/MLOps_Agent/mlops-agent.tar.gz\", \"wb\") as f:\n",
    "     f.write(mlops_agents_tb.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once it is downloaded....and saved to your local filesystem, open/uncompress the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datarobot_mlops_package-6.3.3\n",
      "6.3.3\n"
     ]
    }
   ],
   "source": [
    "!tar -xf /content/mlops-examples/MLOps_Agent/mlops-agent.tar.gz\n",
    "\n",
    "#Save the folder where the whl file is saved\n",
    "with os.popen(\"ls /content\") as pipe:\n",
    "    for line in pipe:\n",
    "        if line.startswith('datarobot_mlops_package'):\n",
    "            mlops_package = line.strip()\n",
    "            version = line.strip()[-5:]\n",
    "print(mlops_package)\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Execute command and install mlops-agent\n",
    "os.system('pip install /content/{}/lib/datarobot_mlops-{}-py2.py3-none-any.whl'.format(mlops_package, version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Quick Start\n",
    "As noted in comment code from the Deployment Integrations tab above, open to get started with the agent software configuration steps:\n",
    "\n",
    ".../{agent install dir}/docs/html/quickstart.html\n",
    "\n",
    "Edit .../{agent install dir}/conf/mlops.agent.conf.yaml to have this (everything else can stay as default if you want)\n",
    "This file is contains the properties used by the MLOps service. Namely, the DataRobpt host url, your authentication token, the spool to use queue data to send to MLOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /tmp/ta: File exists\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Set your DR host:\n",
    "mlopsURL: \"https://app2.datarobot.com\"\n",
    "\n",
    "# Set your API token\n",
    "apiToken: \"NWQ1NDA3ZTdmNTU1Y2Q......\"\n",
    "\n",
    "# Create the spool directory on your system that you want MLOps to use, eg /tmp/ta\n",
    "channelConfigs:\n",
    "  - type: \"FS_SPOOL\"\n",
    "    details: {name: \"bench\", spoolDirectoryPath: \"/tmp/ta\"}\n",
    "\"\"\"\n",
    "!mkdir /tmp/taqw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands to get you started \n",
    "\n",
    "This will allow you to start, get status, and stop the MLOps agent service. You will only need to run start for now.  Run status if you want to check on the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: AGENT_CONFIG_YAML=/Users/thodoris.petropoulos/github/mlops-examples-wip/MLOps Agent/datarobot_mlops_package-6.3.3/conf/mlops.agent.conf.yaml\n",
      "INFO: AGENT_LOG_PROPERTIES=/Users/thodoris.petropoulos/github/mlops-examples-wip/MLOps Agent/datarobot_mlops_package-6.3.3/conf/mlops.log4j2.properties\n",
      "INFO: AGENT_JVM_OPT=-Xmx1G\n",
      "INFO: AGENT_JAR_PATH=/Users/thodoris.petropoulos/github/mlops-examples-wip/MLOps Agent/datarobot_mlops_package-6.3.3/lib/mlops-agent-6.3.3.jar\n",
      "INFO: AGENT_LOG_PATH=/Users/thodoris.petropoulos/github/mlops-examples-wip/MLOps Agent/datarobot_mlops_package-6.3.3/logs/mlops.agent.log\n",
      "\n",
      "Starting MLOps-Agent\n",
      "\n",
      "\n",
      "DataRobot MLOps-Agent is running.\n"
     ]
    }
   ],
   "source": [
    "!bash /content/datarobot_mlops_package-6.3.3/bin/start-agent.sh #Change version based on the downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DataRobot MLOps-Agent is currently running as a service.\n"
     ]
    }
   ],
   "source": [
    "# Shutdown - DON'T RUN THIS CELL, IT'S JUST SHOWING YOU HOW TO SHUTDOWN\n",
    "#!bash datarobot_mlops_package-6.3.3/bin/stop-agent.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an MLOps Model Package for a model and deploy it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a simple RandomForestClassifier model to use for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import pytz\n",
    "import json\n",
    "import yaml\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "TRAINING_DATA = '/content/{}/examples/data/surgical-dataset.csv'.format(mlops_package)\n",
    "\n",
    "df = pd.read_csv(TRAINING_DATA)\n",
    "\n",
    "columns = list(df.columns)\n",
    "arr = df.to_numpy()\n",
    "\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "split_ratio = 0.8\n",
    "prediction_threshold = 0.5\n",
    "\n",
    "train_data_len = int(arr.shape[0] * split_ratio)\n",
    "\n",
    "train_data = arr[:train_data_len, :-1]\n",
    "label = arr[:train_data_len, -1]\n",
    "test_data = arr[train_data_len:, :-1]\n",
    "test_df = df[train_data_len:]\n",
    "\n",
    "# train the model\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
    "clf.fit(train_data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create empty deployment in DataRobot MLOps\n",
    "\n",
    "Using the MLOps client, create a new model package to represent the random forest model we just created.  This includes uploading the traning data and enabling data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training data - datarobot_mlops_package-6.3.3/examples/data/surgical-dataset.csv. This may take some time...\n",
      "Training dataset uploaded. Catalog ID 5fcfa67ddf4fbeea9810fe81.\n",
      "Create model package\n",
      "Deploy model package\n",
      "Enable feature drift\n",
      "\n",
      "Done.\n",
      "DEPLOYMENT_ID=5fcfa6a43b209d9fe9564f39, MODEL_ID=5fcfa6a2ab896936acd514c3\n"
     ]
    }
   ],
   "source": [
    "from datarobot.mlops.mlops import MLOps\n",
    "from datarobot.mlops.common.enums import OutputType\n",
    "from datarobot.mlops.connected.client import MLOpsClient\n",
    "from datarobot.mlops.common.exception import DRConnectedException\n",
    "from datarobot.mlops.constants import Constants\n",
    "\n",
    "# Read the model configuration info from the example.  This is used to create the model package.\n",
    "with open('/content/{}/examples/model_config/surgical_binary_classification.json'.format(mlops_package), \"r\") as f:\n",
    "    model_info = json.loads(f.read())\n",
    "model_info\n",
    "\n",
    "# Read the mlops connection info from the provided example \n",
    "with open('/content/{}/conf/mlops.agent.conf.yaml'.format(mlops_package)) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    agent_yaml_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "MLOPS_URL = agent_yaml_dict['mlopsUrl']\n",
    "API_TOKEN = agent_yaml_dict['apiToken']\n",
    "\n",
    "# Create connected client\n",
    "mlops_connected_client = MLOpsClient(MLOPS_URL, API_TOKEN)\n",
    "\n",
    "# Add training_data to model configuration\n",
    "print(\"Uploading training data - {}. This may take some time...\".format(TRAINING_DATA))\n",
    "dataset_id = mlops_connected_client.upload_dataset(TRAINING_DATA)\n",
    "print(\"Training dataset uploaded. Catalog ID {}.\".format(dataset_id))\n",
    "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
    "\n",
    "# Create the model package\n",
    "print('Create model package')\n",
    "model_pkg_id = mlops_connected_client.create_model_package(model_info)\n",
    "model_pkg = mlops_connected_client.get_model_package(model_pkg_id)\n",
    "model_id = model_pkg[\"modelId\"]\n",
    "\n",
    "# Deploy the model package\n",
    "print('Deploy model package')\n",
    "\n",
    "# Give the deployment a name:\n",
    "DEPLOYMENT_NAME=\"Python binary classification remote model \" + str(datetime.datetime.now())\n",
    "\n",
    "deployment_id = mlops_connected_client.deploy_model_package(model_pkg[\"id\"],\n",
    "                                                            DEPLOYMENT_NAME)\n",
    "\n",
    "# Enable data drift tracking\n",
    "print('Enable feature drift')\n",
    "enable_feature_drift = TRAINING_DATA is not None\n",
    "mlops_connected_client.update_deployment_settings(deployment_id, target_drift=True,\n",
    "                                                  feature_drift=enable_feature_drift)\n",
    "_ = mlops_connected_client.get_deployment_settings(deployment_id)\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
    "\n",
    "DEPLOYMENT_ID = deployment_id\n",
    "MODEL_ID = model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Predictions\n",
    "\n",
    "#### Call the external model's predict fuction and send prediction data to MLOps\n",
    "\n",
    "You can find Deployment and Model ID under `Deployments` --> `Monitoring` Tab. The rest of the code can stay as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote actuals file: actuals.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    " \n",
    "from datarobot.mlops.mlops import MLOps\n",
    "from datarobot.mlops.common.enums import OutputType\n",
    " \n",
    "DEPLOYMENT_ID = 'YOUR_DEPLOYMENT_ID'\n",
    "MODEL_ID = 'YOUR_MODEL_ID'\n",
    "CLASS_NAMES = [\"1\", \"0\"]\n",
    "# Spool directory path must match the Monitoring Agent path configured by admin.\n",
    "SPOOL_DIR = \"/tmp/ta\"\n",
    " \n",
    "\"\"\"\n",
    "This sample code demonstrates usage of the MLOps library.\n",
    "It does not have real data (or even a real model) and should not be run against a real MLOps\n",
    "service.\n",
    "\"\"\"\n",
    "\n",
    "ACTUALS_OUTPUT_FILE = 'actuals.csv'\n",
    " \n",
    "def main(deployment_id, model_id, spool_dir, class_names):\n",
    "    \"\"\"\n",
    "    This is a binary classification algorithm example.\n",
    "    User can call the DataRobot MLOps library functions to report statistics.\n",
    "    \"\"\"\n",
    "    # MLOPS: initialize the MLOps instance\n",
    "    mlops = MLOps() \\\n",
    "        .set_deployment_id(deployment_id) \\\n",
    "        .set_model_id(model_id) \\\n",
    "        .set_filesystem_spooler(spool_dir) \\\n",
    "        .init()\n",
    "\n",
    "    # Get predictions\n",
    "    start_time = time.time()\n",
    "    predictions = clf.predict_proba(test_data).tolist()\n",
    "    num_predictions = len(predictions)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Get assocation id's for the predictions so we can track them with the actuals\n",
    "    def _generate_unique_association_ids(num_samples):\n",
    "        ts = time.time()\n",
    "        return [\"x_{}_{}\".format(ts, i) for i in range(num_samples)]\n",
    "    association_ids = _generate_unique_association_ids(len(test_data))\n",
    " \n",
    "    # MLOPS: report the number of predictions in the request and the execution time.\n",
    "    mlops.report_deployment_stats(num_predictions, end_time - start_time)\n",
    " \n",
    "    # MLOPS: report the predictions data: features, predictions, class_names\n",
    "    mlops.report_predictions_data(features_df=test_df, \n",
    "                                    predictions=predictions, \n",
    "                                    class_names=class_names,\n",
    "                                    association_ids=association_ids)\n",
    "\n",
    "\n",
    "    target_column_name = columns[len(columns) - 1]\n",
    "    target_values = []\n",
    "    orig_labels = test_df[target_column_name].tolist()\n",
    "\n",
    "    print(\"Wrote actuals file: %s\" % ACTUALS_OUTPUT_FILE)\n",
    "    def write_actuals_file(out_filename, test_data_labels, association_ids):\n",
    "        \"\"\"\n",
    "         Generate a CSV file with the association ids and labels, this example\n",
    "         uses a dataset that has labels already.\n",
    "         In a real use case actuals (labels) will show after prediction is done.\n",
    "\n",
    "        :param out_filename:      name of csv file\n",
    "        :param test_data_labels:  actual values (labels)\n",
    "        :param association_ids:   association id list used for predictions\n",
    "        \"\"\"\n",
    "        with open(out_filename, mode=\"w\") as actuals_csv_file:\n",
    "            writer = csv.writer(actuals_csv_file, delimiter=\",\")\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    Constants.ACTUALS_ASSOCIATION_ID_KEY,\n",
    "                    Constants.ACTUALS_VALUE_KEY,\n",
    "                    Constants.ACTUALS_TIMESTAMP_KEY\n",
    "                ]\n",
    "            )\n",
    "            tz = pytz.timezone(\"America/Los_Angeles\")\n",
    "            for (association_id, label) in zip(association_ids, test_data_labels):\n",
    "                actual_timestamp = datetime.datetime.now().replace(tzinfo=tz).isoformat()\n",
    "                writer.writerow([association_id, \"1\" if label else \"0\", actual_timestamp])\n",
    "\n",
    "        \n",
    "    # Write csv file with labels and association Id, when output file is provided\n",
    "    write_actuals_file(ACTUALS_OUTPUT_FILE, orig_labels, association_ids)\n",
    "    \n",
    "    # MLOPS: release MLOps resources when finished.\n",
    "    mlops.shutdown()\n",
    " \n",
    " \n",
    "main(DEPLOYMENT_ID, MODEL_ID, SPOOL_DIR, CLASS_NAMES)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload actuals back to MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect MLOps client\n",
      "Submit actuals\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def _get_correct_actual_value(deployment_type, value):\n",
    "    if deployment_type == \"Regression\":\n",
    "        return float(value)\n",
    "    return str(value)\n",
    "\n",
    "def _get_correct_flag_value(value_str):\n",
    "    if value_str == \"True\":\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def upload_actuals():\n",
    "    print(\"Connect MLOps client\")\n",
    "    mlops_connected_client = MLOpsClient(MLOPS_URL, API_TOKEN)\n",
    "    deployment_type = mlops_connected_client.get_deployment_type(DEPLOYMENT_ID)\n",
    "\n",
    "    actuals = []\n",
    "    with open(ACTUALS_OUTPUT_FILE, mode=\"r\") as actuals_csv_file:\n",
    "        reader = csv.DictReader(actuals_csv_file)\n",
    "        for row in reader:\n",
    "            actual = {}\n",
    "            for key, value in row.items():\n",
    "                if key == Constants.ACTUALS_WAS_ACTED_ON_KEY:\n",
    "                    value = _get_correct_flag_value(value)\n",
    "                if key == Constants.ACTUALS_VALUE_KEY:\n",
    "                    value = _get_correct_actual_value(deployment_type, value)\n",
    "                actual[key] = value\n",
    "            actuals.append(actual)\n",
    "\n",
    "            if len(actuals) == 10000:\n",
    "                mlops_connected_client.submit_actuals(DEPLOYMENT_ID, actuals)\n",
    "                actuals = []\n",
    "\n",
    "    # Submit the actuals\n",
    "    print(\"Submit actuals\")\n",
    "    mlops_connected_client.submit_actuals(DEPLOYMENT_ID, actuals)\n",
    "    \n",
    "    print(\"Done.\")    \n",
    "\n",
    "upload_actuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the mlops service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /content/datarobot_mlops_package-6.3.3/bin/stop-agent.sh #Change version based on the downloaded file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
