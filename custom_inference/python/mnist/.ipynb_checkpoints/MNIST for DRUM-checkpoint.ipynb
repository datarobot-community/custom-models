{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.2 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from -r ./drum/requirements.txt (line 1)) (1.19.2)\n",
      "Requirement already satisfied: keras==2.4.3 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from -r ./drum/requirements.txt (line 2)) (2.4.3)\n",
      "Requirement already satisfied: tensorflow==2.4.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from -r ./drum/requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: h5py in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from keras==2.4.3->-r ./drum/requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from keras==2.4.3->-r ./drum/requirements.txt (line 2)) (1.5.2)\n",
      "Requirement already satisfied: pyyaml in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from keras==2.4.3->-r ./drum/requirements.txt (line 2)) (5.3.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (3.14.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (0.35.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (3.7.4.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (2.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (3.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (4.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0->-r ./drum/requirements.txt (line 3)) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ./drum/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model / data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model = Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "422/422 [==============================] - 14s 32ms/step - loss: 0.7528 - accuracy: 0.7695 - val_loss: 0.0825 - val_accuracy: 0.9782\n",
      "Epoch 2/4\n",
      "422/422 [==============================] - 15s 35ms/step - loss: 0.1251 - accuracy: 0.9618 - val_loss: 0.0636 - val_accuracy: 0.9812\n",
      "Epoch 3/4\n",
      "422/422 [==============================] - 14s 34ms/step - loss: 0.0870 - accuracy: 0.9722 - val_loss: 0.0482 - val_accuracy: 0.9878\n",
      "Epoch 4/4\n",
      "422/422 [==============================] - 14s 34ms/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.0423 - val_accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147e600a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 4\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate with DRUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drum 1.4.8\r\n"
     ]
    }
   ],
   "source": [
    "!drum --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: drum [-h] [--version]\r\n",
      "            {score,fit,perf-test,validation,server,new,push} ...\r\n",
      "\r\n",
      "Run user model\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  {score,fit,perf-test,validation,server,new,push}\r\n",
      "                        Commands\r\n",
      "    score               Run predictions in batch mode\r\n",
      "    fit                 Fit your model to your data\r\n",
      "    perf-test           Run performance tests\r\n",
      "    validation          Run validation checks against the model\r\n",
      "    server              serve the model via REST APIs\r\n",
      "    new                 Create new model/env template\r\n",
      "    push                Add your modeling code into DataRobot\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --version             show program's version number and exit\r\n"
     ]
    }
   ],
   "source": [
    "!drum --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRUM performance test\n",
      "Model:      /Users/tony.martin/Desktop/Jupyter/Projects/MLOps_Unstructured/MNISTforDRUM/drum\n",
      "Data:       /Users/tony.martin/Desktop/Jupyter/Projects/MLOps_Unstructured/MNISTforDRUM/data/mnist.csv\n",
      "# Features: 785\n",
      "Preparing test data...\n",
      "\n",
      "\n",
      "\n",
      "Running test case with timeout: 180\n",
      "Running test case: 2 KB - 1 samples, 100 iterations\n",
      "\u001b[?25lProcessingRunning test case with timeout: 180\n",
      "Running test case: 0.1MB - 50 samples, 50 iterations\n",
      "\u001b[?25lProcessingRunning test case with timeout: 180\n",
      "Running test case: 10MB - 5062 samples, 5 iterations\n",
      "\u001b[?25lProcessingRunning test case with timeout: 180\n",
      "Running test case: 50MB - 25314 samples, 1 iterations\n",
      "\u001b[?25lProcessingTest is done stopping drum server\n",
      "\u001b[m\u001b[?7h\u001b[4l\u001b>\u001b7\u001b[r\u001b[?1;3;4;6l\u001b8Traceback (most recent call last):\n",
      "  File \"/Users/tony.martin/opt/anaconda3/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages/datarobot_drum/drum/main.py\", line 96, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages/datarobot_drum/drum/drum.py\", line 293, in run\n",
      "    CMRunTests(self.options, self.run_mode).performance_test()\n",
      "  File \"/Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages/datarobot_drum/drum/perf_testing.py\", line 473, in performance_test\n",
      "    str_report = PerfTestResultsFormatter(\n",
      "  File \"/Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages/datarobot_drum/drum/perf_testing.py\", line 204, in get_tbl_str\n",
      "    self._table.add_rows(self._rows)\n",
      "  File \"/Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages/texttable.py\", line 404, in add_rows\n",
      "    self.add_row(row)\n",
      "  File \"/Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages/texttable.py\", line 375, in add_row\n",
      "    self._check_row_size(array)\n",
      "  File \"/Users/tony.martin/opt/anaconda3/lib/python3.8/site-packages/texttable.py\", line 526, in _check_row_size\n",
      "    raise ArraySizeError(\"array should contain %d elements\" \\\n",
      "texttable.ArraySizeError: array should contain 8 elements\n"
     ]
    }
   ],
   "source": [
    "!drum perf-test -cd drum \\\n",
    "--input data/mnist.csv \\\n",
    "--target-type unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-18 07:54:36.681184: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-01-18 07:54:36.681398: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-01-18 07:54:36.788851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "0,1,2,3,4,5,6,7,8,9\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n",
      "0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "\n",
      "2021-01-18 07:54:39.607583: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-01-18 07:54:39.607773: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-01-18 07:54:39.710684: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "0,1,2,3,4,5,6,7,8,9\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n",
      "0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "\n",
      "2021-01-18 07:54:42.500943: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-01-18 07:54:42.501189: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-01-18 07:54:42.603917: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "0,1,2,3,4,5,6,7,8,9\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n",
      "0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "\n",
      "2021-01-18 07:54:45.400385: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-01-18 07:54:45.400591: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-01-18 07:54:45.504735: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "0,1,2,3,4,5,6,7,8,9\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n",
      "0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "\n",
      "^C\n",
      "\n",
      "Ctrl+C pressed, aborting drum\n"
     ]
    }
   ],
   "source": [
    "!drum validation -cd drum \\\n",
    "--input data/mnist.csv \\\n",
    "--target-type unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-18 07:54:53.643215: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-01-18 07:54:53.643402: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-01-18 07:54:53.758508: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "0,1,2,3,4,5,6,7,8,9\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n",
      "0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
      "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!drum score \\\n",
    "--code-dir  \\\n",
    "--input data/mnist.csv \\\n",
    "--target-type unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-18 07:54:56.896513: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-01-18 07:54:56.896691: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-01-18 07:54:56.996658: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "      0    1    2    3    4    5    6    7    8    9\n",
      "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "1   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "5   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "6   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "8   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
      "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "10  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "11  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
      "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "13  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "14  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "15  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir drum \\\n",
    "--input data/mnist.csv \\\n",
    "--target-type multiclass \\\n",
    "--class-labels-file drum/classlabels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
